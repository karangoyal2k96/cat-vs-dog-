{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_images=os.listdir(\"./Documents/project/PetImages/Cat\")\n",
    "dog_images=os.listdir(\"./Documents/project/PetImages/Dog/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2000.0\n",
      "2000 500\n"
     ]
    }
   ],
   "source": [
    "dataset=[]\n",
    "\n",
    "for ix in range (int(len(cat_images)*0.1)):\n",
    "    dataset.append(('/home/karan/Documents/project/PetImages/Cat/'+cat_images[ix],0))\n",
    "for ix in range (int(len(dog_images)*0.1)):\n",
    "    dataset.append(('/home/karan/Documents/project/PetImages/Dog/'+dog_images[ix],1))\n",
    "    \n",
    "print (len(dataset))    \n",
    "random.shuffle(dataset)\n",
    "\n",
    "train=[]\n",
    "test=[]\n",
    "print (2500 * 0.8)\n",
    "for ix in range (int(2500*0.8)):\n",
    "    train.append(dataset[ix])\n",
    "for ix in range (500):\n",
    "    test.append(dataset[ix+2000])\n",
    "print len(train),len(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/karan/Documents/project/PetImages/Dog/12049.jpg', 1)\n",
      "('/home/karan/Documents/project/PetImages/Dog/8645.jpg', 1)\n",
      "('/home/karan/Documents/project/PetImages/Cat/1849.jpg', 0)\n",
      "('/home/karan/Documents/project/PetImages/Dog/9862.jpg', 1)\n",
      "('/home/karan/Documents/project/PetImages/Cat/7888.jpg', 0)\n",
      "('/home/karan/Documents/project/PetImages/Cat/4480.jpg', 0)\n",
      "('/home/karan/Documents/project/PetImages/Dog/4219.jpg', 1)\n",
      "('/home/karan/Documents/project/PetImages/Cat/12489.jpg', 0)\n",
      "('/home/karan/Documents/project/PetImages/Dog/4108.jpg', 1)\n",
      "('/home/karan/Documents/project/PetImages/Dog/9667.jpg', 1)\n"
     ]
    }
   ],
   "source": [
    "for ix in range (10):\n",
    "    print dataset[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/karan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efe0062cc10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "print os.getcwd()\n",
    "k=cv2.imread('./Documents/project/PetImages/Dog/1170.jpg')\n",
    "plt.imshow(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from scipy.misc import imread\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from scipy.misc import imresize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img=[]\n",
    "for i in range(len(train)):\n",
    "\n",
    "    temp_img=image.load_img(train[i][0],target_size=(224,224))\n",
    "\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "\n",
    "    train_img.append(temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img=np.array(train_img)\n",
    "train_img=preprocess_input(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=[]\n",
    "for i in range(len(test)):\n",
    "\n",
    "    temp_img=image.load_img(test[i][0],target_size=(224,224))\n",
    "\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "\n",
    "    test_img.append(temp_img)\n",
    "\n",
    "test_img=np.array(test_img)\n",
    "test_img=preprocess_input(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....................................................x...................................................................x....................................s...s......ss.....................ss...................................................................................sss...........................F..................................x....x........................x.....x.......................................ssssssssss.............F....\n",
      "======================================================================\n",
      "FAIL: test_out_of_order_offsets (h5py.tests.old.test_h5t.TestCompound)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/h5py/tests/old/test_h5t.py\", line 61, in test_out_of_order_offsets\n",
      "    self.assertEqual(tid.dtype, expected_dtype)\n",
      "AssertionError: dtype({'names':['f1','f3','f2'], 'formats':['<f4','<f8','<i4'], 'offsets':[0,8,16], 'itemsize':20}) != dtype({'names':['f1','f2','f3'], 'formats':['<f4','<i4','<f8'], 'offsets':[0,16,8], 'itemsize':20})\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_out_of_order_offsets (h5py.tests.hl.test_datatype.TestOffsets)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/h5py/tests/hl/test_datatype.py\", line 198, in test_out_of_order_offsets\n",
      "    self.assertArrayEqual(fd['data'], data)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/h5py/tests/common.py\", line 124, in assertArrayEqual\n",
      "    \"Dtype mismatch (%s vs %s)%s\" % (dset.dtype, arr.dtype, message)\n",
      "AssertionError: Dtype mismatch ({'names':['f1','f3','f2'], 'formats':['<f4','<f8','<i4'], 'offsets':[0,8,16], 'itemsize':20} vs {'names':['f1','f2','f3'], 'formats':['<f4','<i4','<f8'], 'offsets':[0,16,8], 'itemsize':20})\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 446 tests in 5.208s\n",
      "\n",
      "FAILED (failures=2, skipped=19, expected failures=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=446 errors=0 failures=2>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train=model.predict(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=features_train.reshape(2000,25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=np.array(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "train_y=np.asarray(dummy[:,1])\n",
    "print train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '1' '0' ... '0' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=pd.get_dummies(train_y)\n",
    "train_y=np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_x,train_y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(1000, input_dim=25088, activation='relu',kernel_initializer='uniform'))\n",
    "keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(500,input_dim=1000,activation='sigmoid'))\n",
    "keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(150,input_dim=500,activation='sigmoid'))\n",
    "keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(units=2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/20\n",
      "1400/1400 [==============================] - 14s 10ms/step - loss: 0.4570 - acc: 0.7907 - val_loss: 0.1475 - val_acc: 0.9667\n",
      "Epoch 2/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 0.0888 - acc: 0.9779 - val_loss: 0.0624 - val_acc: 0.9817\n",
      "Epoch 3/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 0.0309 - acc: 0.9950 - val_loss: 0.0485 - val_acc: 0.9883\n",
      "Epoch 4/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 0.0142 - acc: 0.9971 - val_loss: 0.0451 - val_acc: 0.9833\n",
      "Epoch 5/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0454 - val_acc: 0.9867\n",
      "Epoch 6/20\n",
      "1400/1400 [==============================] - 12s 9ms/step - loss: 0.0050 - acc: 0.9993 - val_loss: 0.0402 - val_acc: 0.9833\n",
      "Epoch 7/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0391 - val_acc: 0.9850\n",
      "Epoch 8/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 0.9850\n",
      "Epoch 9/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 0.9883\n",
      "Epoch 10/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "Epoch 11/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 9.5440e-04 - acc: 1.0000 - val_loss: 0.0432 - val_acc: 0.9883\n",
      "Epoch 12/20\n",
      "1400/1400 [==============================] - 12s 8ms/step - loss: 8.5327e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9883\n",
      "Epoch 13/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 7.7291e-04 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 0.9883\n",
      "Epoch 14/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 7.0700e-04 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 0.9883\n",
      "Epoch 15/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 6.5303e-04 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9883\n",
      "Epoch 16/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 6.0552e-04 - acc: 1.0000 - val_loss: 0.0480 - val_acc: 0.9883\n",
      "Epoch 17/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 5.6544e-04 - acc: 1.0000 - val_loss: 0.0484 - val_acc: 0.9883\n",
      "Epoch 18/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 5.3048e-04 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9883\n",
      "Epoch 19/20\n",
      "1400/1400 [==============================] - 11s 8ms/step - loss: 4.9920e-04 - acc: 1.0000 - val_loss: 0.0495 - val_acc: 0.9883\n",
      "Epoch 20/20\n",
      "1400/1400 [==============================] - 10s 7ms/step - loss: 4.7131e-04 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc7fb80b50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=20, batch_size=128,validation_data=(X_valid,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
